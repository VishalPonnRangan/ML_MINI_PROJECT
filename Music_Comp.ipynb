{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7681d107-3202-45e0-8208-a431654a321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7263a07-860d-4a0c-9c23-14d5c4dadb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function to read MIDI files\n",
    "def read_midi(file):\n",
    "    \n",
    "    print(\"Loading Music File:\",file)\n",
    "    \n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    #parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "  \n",
    "    #grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    #Looping over all the instruments\n",
    "    for part in s2.parts:\n",
    "    \n",
    "        #select elements of only piano\n",
    "        if 'Piano' in str(part): \n",
    "        \n",
    "            notes_to_parse = part.recurse() \n",
    "      \n",
    "            #finding whether a particular element is note or a chord\n",
    "            for element in notes_to_parse:\n",
    "                \n",
    "                #note\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                \n",
    "                #chord\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d17859d-1a32-476c-bf8d-b77856a0b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10ef4fbc-0bf9-4078-986a-8f93c3677738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: Zucchero/Donne.mid\n",
      "Loading Music File: Zucchero/Diamante.3.mid\n",
      "Loading Music File: Zucchero/Senza Una Donna.3.mid\n",
      "Loading Music File: Zucchero/Baila (Sexy Thing).mid\n",
      "Loading Music File: Zucchero/Senza Una Donna.2.mid\n",
      "Loading Music File: Zucchero/Hey Man.1.mid\n",
      "Loading Music File: Zucchero/Diamante.2.mid\n",
      "Loading Music File: Zucchero/Canzone triste (Canzone d'amore).mid\n",
      "Loading Music File: Zucchero/L'urlo.mid\n",
      "Loading Music File: Zucchero/Muoio per te.mid\n",
      "Loading Music File: Zucchero/Il volo.mid\n",
      "Loading Music File: Zucchero/Diamante.mid\n",
      "Loading Music File: Zucchero/Senza Una Donna.1.mid\n",
      "Loading Music File: Zucchero/Hey Man.2.mid\n",
      "Loading Music File: Zucchero/Puro amore.mid\n",
      "Loading Music File: Zucchero/Diamante.1.mid\n",
      "Loading Music File: Zucchero/Pippo.1.mid\n",
      "Loading Music File: Zucchero/Pane e sale.mid\n",
      "Loading Music File: Zucchero/Cosi celeste.mid\n",
      "Loading Music File: Zucchero/Senza Una Donna.5.mid\n",
      "Loading Music File: Zucchero/Senza Una Donna.4.mid\n",
      "Loading Music File: Zucchero/Diamante.4.mid\n",
      "Loading Music File: Zucchero/Non ti sopporto piu.mid\n",
      "Loading Music File: Zucchero/Senza Una Donna.6.mid\n",
      "Loading Music File: Zucchero/Senza Una Donna.7.mid\n",
      "Loading Music File: Zucchero/Madre dolcissima.mid\n",
      "Loading Music File: Zucchero/Hai scelto me.mid\n",
      "Loading Music File: Zucchero/Come il sole all'improvviso.1.mid\n",
      "Loading Music File: Zucchero/Cosi celeste.2.mid\n",
      "Loading Music File: Zucchero/Alleluja.mid\n",
      "Loading Music File: Zucchero/Con le mani.3.mid\n",
      "Loading Music File: Zucchero/Con le mani.2.mid\n",
      "Loading Music File: Zucchero/Dune mosse.2.mid\n",
      "Loading Music File: Zucchero/Rispetto.1.mid\n",
      "Loading Music File: Zucchero/Il mare impetuoso al tramonto sali sulla luna e dietro una tendina di stelle....mid\n",
      "Loading Music File: Zucchero/Cosi celeste.1.mid\n",
      "Loading Music File: Zucchero/Come il sole all'improvviso.2.mid\n",
      "Loading Music File: Zucchero/Con le mani.1.mid\n",
      "Loading Music File: Zucchero/Dune mosse.1.mid\n",
      "Loading Music File: Zucchero/Come il sole all'improvviso.3.mid\n",
      "Loading Music File: Zucchero/Music in Me.mid\n",
      "Loading Music File: Zucchero/Per colpa di chi.1.mid\n",
      "Loading Music File: Zucchero/Nice (Nietzsche) che dice.1.mid\n",
      "Loading Music File: Zucchero/Madre dolcissima.2.mid\n",
      "Loading Music File: Zucchero/Puro amore.1.mid\n",
      "Loading Music File: Zucchero/Come il sole all'improvviso.4.mid\n",
      "Loading Music File: Zucchero/Per colpa di chi.2.mid\n",
      "Loading Music File: Zucchero/Back 2 U.mid\n",
      "Loading Music File: Zucchero/Bambino io, bambino tu (Legenda).mid\n",
      "Loading Music File: Zucchero/Per colpa di chi.3.mid\n",
      "Loading Music File: Zucchero/Madre dolcissima.1.mid\n",
      "Loading Music File: Zucchero/Ali d'oro.mid\n",
      "Loading Music File: Zucchero/Solo una sana e consapevole libidine salva il giovane dallo stress e dall'Azione Cattolica.mid\n",
      "Loading Music File: Zucchero/Miserere.1.mid\n",
      "Loading Music File: Zucchero/Diavolo in me.5.mid\n",
      "Loading Music File: Zucchero/Diavolo in me.4.mid\n",
      "Loading Music File: Zucchero/Senza Una Donna.mid\n",
      "Loading Music File: Zucchero/Un piccolo aiuto (feat. Gerard Depardieu).mid\n",
      "Loading Music File: Zucchero/Iruben me.mid\n",
      "Loading Music File: Zucchero/Pippo.mid\n",
      "Loading Music File: Zucchero/Diavolo in me.3.mid\n",
      "Loading Music File: Zucchero/Hey Man.mid\n",
      "Loading Music File: Zucchero/Ridammi il Sole.mid\n",
      "Loading Music File: Zucchero/Diavolo in me.2.mid\n",
      "Loading Music File: Zucchero/Datemi una pompa.mid\n",
      "Loading Music File: Zucchero/You Make Me Feel Loved.mid\n",
      "Loading Music File: Zucchero/Diavolo in me.mid\n",
      "Loading Music File: Zucchero/Diavolo in me.1.mid\n",
      "Loading Music File: Zucchero/Rispetto.mid\n",
      "Loading Music File: Zucchero/Overdose (d'amore).3.mid\n",
      "Loading Music File: Zucchero/Il mare impetuoso al tramonto sali sulla luna e dietro una tendina di stelle....3.mid\n",
      "Loading Music File: Zucchero/Scintille.mid\n",
      "Loading Music File: Zucchero/Torna a casa.mid\n",
      "Loading Music File: Zucchero/Il volo.1.mid\n",
      "Loading Music File: Zucchero/Donne.1.mid\n",
      "Loading Music File: Zucchero/Il mare impetuoso al tramonto sali sulla luna e dietro una tendina di stelle....2.mid\n",
      "Loading Music File: Zucchero/Blu.1.mid\n",
      "Loading Music File: Zucchero/Overdose (d'amore).2.mid\n",
      "Loading Music File: Zucchero/Come il sole all'improvviso.mid\n",
      "Loading Music File: Zucchero/Blu.3.mid\n",
      "Loading Music File: Zucchero/Con le mani.mid\n",
      "Loading Music File: Zucchero/Donne.3.mid\n",
      "Loading Music File: Zucchero/Eppure non t'amo.mid\n",
      "Loading Music File: Zucchero/Il volo.2.mid\n",
      "Loading Music File: Zucchero/Donne.2.mid\n",
      "Loading Music File: Zucchero/Il mare impetuoso al tramonto sali sulla luna e dietro una tendina di stelle....1.mid\n",
      "Loading Music File: Zucchero/Blu.2.mid\n",
      "Loading Music File: Zucchero/Overdose (d'amore).1.mid\n",
      "Loading Music File: Zucchero/Voodoo voodoo.mid\n",
      "Loading Music File: Zucchero/Voodoo voodoo.1.mid\n",
      "Loading Music File: Zucchero/Miserere.mid\n",
      "Loading Music File: Zucchero/Menta e rosmarino.mid\n",
      "Loading Music File: Zucchero/Dune mosse.mid\n",
      "Loading Music File: Zucchero/It's All Right (La promessa).mid\n",
      "Loading Music File: Zucchero/Donne.4.mid\n",
      "Loading Music File: Zucchero/Nice (Nietzsche) che dice.mid\n",
      "Loading Music File: Zucchero/Overdose (d'amore).mid\n",
      "Loading Music File: Zucchero/Voodoo voodoo.2.mid\n",
      "Loading Music File: Zucchero/Per colpa di chi.mid\n",
      "Loading Music File: Zucchero/Blu.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8g/3bv0_0hn2jd8bpwk5_37ryyc0000gp/T/ipykernel_1705/1880616534.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  notes_array = np.array([read_midi(path+i) for i in files])\n"
     ]
    }
   ],
   "source": [
    "#for listing down the file names\n",
    "import os\n",
    "\n",
    "#Array Processing\n",
    "import numpy as np\n",
    "\n",
    "#specify the path\n",
    "path = r'Zucchero/'\n",
    "\n",
    "#read all the filenames\n",
    "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "\n",
    "#reading each midi file\n",
    "notes_array = np.array([read_midi(path+i) for i in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86d58281-f3f1-477d-bda6-91a0c0771e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381\n"
     ]
    }
   ],
   "source": [
    "#converting 2D array into 1D array\n",
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "#No. of unique notes\n",
    "unique_notes = list(set(notes_))\n",
    "print(len(unique_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a97a2cae-b696-4eaf-a359-7b2a0bfc2a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([321.,  25.,  17.,   6.,   3.,   5.,   2.,   1.,   0.,   1.]),\n",
       " array([1.000e+00, 1.038e+02, 2.066e+02, 3.094e+02, 4.122e+02, 5.150e+02,\n",
       "        6.178e+02, 7.206e+02, 8.234e+02, 9.262e+02, 1.029e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 319
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing library\n",
    "from collections import Counter\n",
    "\n",
    "#computing frequency of each note\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "#library for visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#consider only the frequencies\n",
    "no=[count for _,count in freq.items()]\n",
    "\n",
    "#set the figure size\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "#plot\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9945d80b-f2e8-4e03-9a96-52abb7c7edfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0287f95c-c77a-40d5-9e22-e1f9fcf25d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8g/3bv0_0hn2jd8bpwk5_37ryyc0000gp/T/ipykernel_1705/2871568428.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  new_music = np.array(new_music)\n"
     ]
    }
   ],
   "source": [
    "new_music=[]\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp=[]\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)            \n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aefea77e-2847-4295-9a5d-16058157d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
    "        \n",
    "        #preparing input and output sequences\n",
    "        input_ = note_[i:i + no_of_timesteps]\n",
    "        output = note_[i + no_of_timesteps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6c93171-39b6-4158-ac64-387773397366",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20444249-62ba-4409-bda4-ee79d3e80e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing input sequences\n",
    "x_seq=[]\n",
    "for i in x:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        #assigning unique integer to every note\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f37717b-cadf-4292-9b81-f4c18f2e8c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq=np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c51ce0ab-eeee-48b8-bd1e-f54f7c0952a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60a2df1a-2704-4b76-8c36-23be41d9b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lstm():\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(128,return_sequences=True))\n",
    "  model.add(LSTM(128))\n",
    "  model.add(Dense(256))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dense(n_vocab))\n",
    "  model.add(Activation('softmax'))\n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "684c5604-5e9c-42fa-a97e-dd49572ae483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 32, 100)           8900      \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 32, 64)            19264     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 64)            0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 16, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 8, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 8, 256)            98560     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 4, 256)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 256)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 89)                22873     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 240,093\n",
      "Trainable params: 240,093\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "    \n",
    "#embedding layer\n",
    "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c79e312-2e90-491a-95ff-18d23ab2c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc=ModelCheckpoint('best_model.h5py', monitor='val_loss', mode='min', save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c2ec3bc-174b-457f-a9aa-600197163dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 3.7904\n",
      "Epoch 1: val_loss improved from inf to 3.42183, saving model to best_model.h5py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-22 12:21:20.202088: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 14s 108ms/step - loss: 3.7904 - val_loss: 3.4218\n",
      "Epoch 2/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 3.0890\n",
      "Epoch 2: val_loss improved from 3.42183 to 3.12157, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 11s 100ms/step - loss: 3.0889 - val_loss: 3.1216\n",
      "Epoch 3/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 2.8426\n",
      "Epoch 3: val_loss improved from 3.12157 to 2.96295, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 12s 105ms/step - loss: 2.8429 - val_loss: 2.9630\n",
      "Epoch 4/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 2.7275\n",
      "Epoch 4: val_loss improved from 2.96295 to 2.84816, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 11s 102ms/step - loss: 2.7274 - val_loss: 2.8482\n",
      "Epoch 5/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 2.6232\n",
      "Epoch 5: val_loss improved from 2.84816 to 2.79802, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 11s 102ms/step - loss: 2.6230 - val_loss: 2.7980\n",
      "Epoch 6/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 2.5368\n",
      "Epoch 6: val_loss improved from 2.79802 to 2.69792, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 12s 106ms/step - loss: 2.5370 - val_loss: 2.6979\n",
      "Epoch 7/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 2.4612\n",
      "Epoch 7: val_loss improved from 2.69792 to 2.67166, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 12s 110ms/step - loss: 2.4609 - val_loss: 2.6717\n",
      "Epoch 8/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 2.3966\n",
      "Epoch 8: val_loss improved from 2.67166 to 2.54885, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 12s 106ms/step - loss: 2.3964 - val_loss: 2.5489\n",
      "Epoch 9/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 2.3306\n",
      "Epoch 9: val_loss improved from 2.54885 to 2.54620, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 13s 112ms/step - loss: 2.3301 - val_loss: 2.5462\n",
      "Epoch 10/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 2.2682\n",
      "Epoch 10: val_loss improved from 2.54620 to 2.47763, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 13s 113ms/step - loss: 2.2683 - val_loss: 2.4776\n",
      "Epoch 11/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 2.2083\n",
      "Epoch 11: val_loss improved from 2.47763 to 2.43249, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 11s 99ms/step - loss: 2.2081 - val_loss: 2.4325\n",
      "Epoch 12/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 2.1529\n",
      "Epoch 12: val_loss improved from 2.43249 to 2.39233, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 13s 115ms/step - loss: 2.1531 - val_loss: 2.3923\n",
      "Epoch 13/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 2.1101\n",
      "Epoch 13: val_loss improved from 2.39233 to 2.34619, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 11s 95ms/step - loss: 2.1106 - val_loss: 2.3462\n",
      "Epoch 14/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 2.0680\n",
      "Epoch 14: val_loss improved from 2.34619 to 2.30447, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 11s 98ms/step - loss: 2.0676 - val_loss: 2.3045\n",
      "Epoch 15/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 2.0134\n",
      "Epoch 15: val_loss improved from 2.30447 to 2.29751, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 11s 101ms/step - loss: 2.0136 - val_loss: 2.2975\n",
      "Epoch 16/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.9728\n",
      "Epoch 16: val_loss improved from 2.29751 to 2.27121, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 11s 96ms/step - loss: 1.9729 - val_loss: 2.2712\n",
      "Epoch 17/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.9257\n",
      "Epoch 17: val_loss improved from 2.27121 to 2.20014, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 12s 107ms/step - loss: 1.9252 - val_loss: 2.2001\n",
      "Epoch 18/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.8965\n",
      "Epoch 18: val_loss improved from 2.20014 to 2.17242, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 11s 102ms/step - loss: 1.8967 - val_loss: 2.1724\n",
      "Epoch 19/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.8561\n",
      "Epoch 19: val_loss improved from 2.17242 to 2.16963, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 12s 104ms/step - loss: 1.8561 - val_loss: 2.1696\n",
      "Epoch 20/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.8172\n",
      "Epoch 20: val_loss improved from 2.16963 to 2.14454, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 12s 111ms/step - loss: 1.8171 - val_loss: 2.1445\n",
      "Epoch 21/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.7808\n",
      "Epoch 21: val_loss improved from 2.14454 to 2.10214, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 12s 104ms/step - loss: 1.7809 - val_loss: 2.1021\n",
      "Epoch 22/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.7460\n",
      "Epoch 22: val_loss improved from 2.10214 to 2.09731, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 12s 107ms/step - loss: 1.7460 - val_loss: 2.0973\n",
      "Epoch 23/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.7233\n",
      "Epoch 23: val_loss improved from 2.09731 to 2.08343, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 11s 102ms/step - loss: 1.7232 - val_loss: 2.0834\n",
      "Epoch 24/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.6961\n",
      "Epoch 24: val_loss improved from 2.08343 to 2.07677, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 11s 99ms/step - loss: 1.6956 - val_loss: 2.0768\n",
      "Epoch 25/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.6600\n",
      "Epoch 25: val_loss improved from 2.07677 to 2.04123, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 14s 124ms/step - loss: 1.6602 - val_loss: 2.0412\n",
      "Epoch 26/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.6266\n",
      "Epoch 26: val_loss improved from 2.04123 to 2.01821, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 11s 100ms/step - loss: 1.6265 - val_loss: 2.0182\n",
      "Epoch 27/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.6129\n",
      "Epoch 27: val_loss did not improve from 2.01821\n",
      "112/112 [==============================] - 9s 83ms/step - loss: 1.6130 - val_loss: 2.0235\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 1.5745\n",
      "Epoch 28: val_loss improved from 2.01821 to 2.00683, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 13s 112ms/step - loss: 1.5745 - val_loss: 2.0068\n",
      "Epoch 29/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.5683\n",
      "Epoch 29: val_loss improved from 2.00683 to 1.99638, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 11s 102ms/step - loss: 1.5690 - val_loss: 1.9964\n",
      "Epoch 30/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.5429\n",
      "Epoch 30: val_loss improved from 1.99638 to 1.98847, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 12s 110ms/step - loss: 1.5425 - val_loss: 1.9885\n",
      "Epoch 31/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.5224\n",
      "Epoch 31: val_loss improved from 1.98847 to 1.98690, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 12s 107ms/step - loss: 1.5230 - val_loss: 1.9869\n",
      "Epoch 32/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.4994\n",
      "Epoch 32: val_loss improved from 1.98690 to 1.96706, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 13s 114ms/step - loss: 1.4991 - val_loss: 1.9671\n",
      "Epoch 33/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.4711\n",
      "Epoch 33: val_loss improved from 1.96706 to 1.95577, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 12s 105ms/step - loss: 1.4715 - val_loss: 1.9558\n",
      "Epoch 34/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.4521\n",
      "Epoch 34: val_loss improved from 1.95577 to 1.94172, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 12s 104ms/step - loss: 1.4526 - val_loss: 1.9417\n",
      "Epoch 35/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.4329\n",
      "Epoch 35: val_loss did not improve from 1.94172\n",
      "112/112 [==============================] - 11s 94ms/step - loss: 1.4327 - val_loss: 1.9475\n",
      "Epoch 36/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.4042\n",
      "Epoch 36: val_loss improved from 1.94172 to 1.93795, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 12s 110ms/step - loss: 1.4043 - val_loss: 1.9379\n",
      "Epoch 37/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.3984\n",
      "Epoch 37: val_loss improved from 1.93795 to 1.92574, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 12s 110ms/step - loss: 1.3986 - val_loss: 1.9257\n",
      "Epoch 38/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.3796\n",
      "Epoch 38: val_loss did not improve from 1.92574\n",
      "112/112 [==============================] - 11s 95ms/step - loss: 1.3805 - val_loss: 1.9324\n",
      "Epoch 39/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.3594\n",
      "Epoch 39: val_loss improved from 1.92574 to 1.91690, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 14s 122ms/step - loss: 1.3602 - val_loss: 1.9169\n",
      "Epoch 40/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.3460\n",
      "Epoch 40: val_loss did not improve from 1.91690\n",
      "112/112 [==============================] - 11s 102ms/step - loss: 1.3460 - val_loss: 1.9190\n",
      "Epoch 41/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.3337\n",
      "Epoch 41: val_loss improved from 1.91690 to 1.90322, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 14s 125ms/step - loss: 1.3336 - val_loss: 1.9032\n",
      "Epoch 42/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.3177\n",
      "Epoch 42: val_loss did not improve from 1.90322\n",
      "112/112 [==============================] - 11s 99ms/step - loss: 1.3176 - val_loss: 1.9163\n",
      "Epoch 43/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.3234\n",
      "Epoch 43: val_loss did not improve from 1.90322\n",
      "112/112 [==============================] - 12s 105ms/step - loss: 1.3236 - val_loss: 1.9095\n",
      "Epoch 44/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.2947\n",
      "Epoch 44: val_loss improved from 1.90322 to 1.88927, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 14s 123ms/step - loss: 1.2942 - val_loss: 1.8893\n",
      "Epoch 45/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.2831\n",
      "Epoch 45: val_loss did not improve from 1.88927\n",
      "112/112 [==============================] - 12s 103ms/step - loss: 1.2826 - val_loss: 1.9041\n",
      "Epoch 46/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.2585\n",
      "Epoch 46: val_loss did not improve from 1.88927\n",
      "112/112 [==============================] - 11s 101ms/step - loss: 1.2591 - val_loss: 1.8969\n",
      "Epoch 47/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.2559\n",
      "Epoch 47: val_loss did not improve from 1.88927\n",
      "112/112 [==============================] - 11s 97ms/step - loss: 1.2563 - val_loss: 1.8931\n",
      "Epoch 48/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.2451\n",
      "Epoch 48: val_loss improved from 1.88927 to 1.87961, saving model to best_model.h5py\n",
      "INFO:tensorflow:Assets written to: best_model.h5py/assets\n",
      "112/112 [==============================] - 14s 127ms/step - loss: 1.2455 - val_loss: 1.8796\n",
      "Epoch 49/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.2248\n",
      "Epoch 49: val_loss did not improve from 1.87961\n",
      "112/112 [==============================] - 11s 95ms/step - loss: 1.2250 - val_loss: 1.8926\n",
      "Epoch 50/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 1.2083\n",
      "Epoch 50: val_loss did not improve from 1.87961\n",
      "112/112 [==============================] - 11s 96ms/step - loss: 1.2084 - val_loss: 1.8965\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "520fd378-decb-43be-b202-a918b4ec696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading best model\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9febf7bc-35db-41d4-a7ca-62468826aa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 45, 45, 56, 4, 81, 87, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "\n",
    "random_music = x_val[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(10):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_of_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1557ab0c-9a1e-4ec2-b41c-0090dd582b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f498837-daf9-4273-8aa5-65e17b99aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fea086a6-58c6-4483-8215-3139affdc685",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6876027c-93c5-499f-b065-5deb0c1a39f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
